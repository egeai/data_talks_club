{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Homework\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q1. Downloading the data\n",
    "[The data link address of NYC Dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\n",
    "\n",
    "Read the data for January. How many columns are there?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T05:27:09.433320Z",
     "start_time": "2023-05-20T05:27:09.413978Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# This is January data of NYC Dataset\n",
    "nyc_df_train = pd.read_parquet(\"../data/yellow_tripdata_2022-01.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:33:23.189104Z",
     "start_time": "2023-05-20T09:33:22.154190Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "print(\"Number of columns are: \", nyc_df_train.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:33:24.665510Z",
     "start_time": "2023-05-20T09:33:24.654282Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q2. Computing duration\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes.\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "Let's first check the info of the dataframe to see the type of `tpep_dropoff_datetime` and `tpep_pickup_datetime` columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "nyc_df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:33:26.249841Z",
     "start_time": "2023-05-20T09:33:26.221014Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we will find the `duration` of the trips in minutes, the date time type is what we are looking for. We don't need to convert it to datetime type."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "nyc_df_train[\"duration\"] = nyc_df_train[\"tpep_dropoff_datetime\"]-nyc_df_train[\"tpep_pickup_datetime\"]\n",
    "nyc_df_train.duration = nyc_df_train.duration.apply(lambda td: td.total_seconds()/60)\n",
    "nyc_df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:33:49.013374Z",
     "start_time": "2023-05-20T09:33:27.913647Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "import math\n",
    "\"\"\"\n",
    "The calculation of standard deviation is described as;\n",
    "std = sqrt(mean(x)) ,\n",
    "where x = abs(a - a.mean())**2 . The average squared deviation is typically calculated as x.sum() / N , where N = len(x)\n",
    "\"\"\"\n",
    "\n",
    "# according to that calculation description we can define our solution like below\n",
    "x = abs(nyc_df_train.duration-nyc_df_train.duration.mean())**2\n",
    "print(math.sqrt(x.sum() / len(x)))\n",
    "\n",
    "# we can also choose the easy way and use built-in function\n",
    "print(nyc_df_train.duration.std())\n",
    "\n",
    "# 46.45 is the right answer for this question"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:33:49.246475Z",
     "start_time": "2023-05-20T09:33:49.011745Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q3. Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# The statistics of the duration column is:\n",
    "nyc_df_train.duration.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:33:49.412919Z",
     "start_time": "2023-05-20T09:33:49.135283Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Do we have null values in duration records? No\n",
    "nyc_df_train.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:33:50.704176Z",
     "start_time": "2023-05-20T09:33:49.283673Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# One of the best ways to describe a variable is to report the values that appear in the\n",
    "# dataset and how many times each value appears. This is called distribution of the variable.\n",
    "sns.histplot(nyc_df_train.duration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:36:32.610092Z",
     "start_time": "2023-05-20T09:33:50.705772Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "before_dropping_outliers = nyc_df_train.shape[0]\n",
    "nyc_dataframe = nyc_df_train[(nyc_df_train.duration >= 1) & (nyc_df_train.duration <= 60)]\n",
    "after_dropping_outliers = nyc_dataframe.shape[0]\n",
    "\n",
    "fraction_left = (after_dropping_outliers / before_dropping_outliers)*100\n",
    "\n",
    "# Let's look at the duration's histplot, after dropping outliers\n",
    "print(sns.histplot(nyc_dataframe.duration))\n",
    "\n",
    "print(f\"{fraction_left} of the records left, after dropping outliers\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:36:56.409112Z",
     "start_time": "2023-05-20T09:36:32.607152Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "What's the dimensionality of this matrix (number of columns)?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Turn the dataframe into a list of dictionaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# initialize the Dictionary Vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# let's choose our categorical fields\n",
    "categorical_columns = ['PULocationID', 'DOLocationID']\n",
    "nyc_dataframe[categorical_columns] = nyc_dataframe[categorical_columns].astype(str)\n",
    "\n",
    "# turn selected columns into a list of dictionaries\n",
    "train_dicts = nyc_dataframe[categorical_columns].to_dict(orient='records')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:36:57.104846Z",
     "start_time": "2023-05-20T09:36:56.006468Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Fit a dictionary vectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "X_train = dv.fit_transform(train_dicts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:36:57.114008Z",
     "start_time": "2023-05-20T09:36:56.011146Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Get a feature matrix from it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "print(f\"The dimensionality of this matrix is, {X_train.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:36:57.114922Z",
     "start_time": "2023-05-20T09:36:56.105469Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "print(f\"The number of columns of this matrix is, {X_train.shape[1]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:36:57.115528Z",
     "start_time": "2023-05-20T09:36:56.106911Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q5. Training a model\n",
    "Now let's use the feature matrix from the previous step to train a model. What's the RMSE on train?\n",
    "#### 1. Train a plain linear regression model with default parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# import Linear Regression and mean_squared_error from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# initialize linear regression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# define target field\n",
    "y = 'duration'\n",
    "\n",
    "# select target values from original dataframe to train\n",
    "y_train = nyc_dataframe[y].values\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:37:38.137504Z",
     "start_time": "2023-05-20T09:36:56.107399Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "####  2. Calculate the RMSE of the model on the training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# to calculate root mean squared error, we need to get predictions\n",
    "y_predictions = lr.predict(X_train)\n",
    "mean_squared_error(y_train, y_predictions, squared=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T09:49:24.861016Z",
     "start_time": "2023-05-20T09:49:24.776443Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2022).\n",
    "What's the RMSE on validation?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# This is NYC Dataset of February. We will use it for validation\n",
    "nyc_df_val = pd.read_parquet('../data/yellow_tripdata_2022-02.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T10:23:25.407326Z",
     "start_time": "2023-05-20T10:23:23.887034Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "print(\"Number of columns are: \", nyc_df_val.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T10:23:35.077175Z",
     "start_time": "2023-05-20T10:23:35.064120Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# Let's check info\n",
    "nyc_df_val.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T10:23:36.125963Z",
     "start_time": "2023-05-20T10:23:36.103904Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# choose the same arrange of data as train dataset\n",
    "nyc_df_val[\"duration\"] = nyc_df_val.tpep_dropoff_datetime - nyc_df_val.tpep_pickup_datetime\n",
    "nyc_df_val.duration = nyc_df_val.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "nyc_dataframe_val = nyc_df_val[(nyc_df_val.duration >= 1) & (nyc_df_val.duration <= 60)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T10:24:01.661903Z",
     "start_time": "2023-05-20T10:23:46.898651Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "nyc_dataframe_val.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T10:24:03.965783Z",
     "start_time": "2023-05-20T10:24:03.943589Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# turn selected columns into a list of dictionaries\n",
    "nyc_dataframe_val[categorical_columns] = nyc_dataframe_val[categorical_columns].astype(str)\n",
    "val_dicts = nyc_dataframe_val[categorical_columns].to_dict(orient='records')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T10:24:31.349175Z",
     "start_time": "2023-05-20T10:24:18.963882Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# This time we just do the transform without fitting to get X_val\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "# select target values for validation\n",
    "y_val = nyc_dataframe_val['duration'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T10:24:41.208948Z",
     "start_time": "2023-05-20T10:24:32.894482Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# Let's make predictions\n",
    "y_val_predictions = lr.predict(X_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T10:24:42.688352Z",
     "start_time": "2023-05-20T10:24:42.636596Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# ...and lastly, we check the score\n",
    "mean_squared_error(y_val, y_val_predictions, squared=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T10:24:45.660014Z",
     "start_time": "2023-05-20T10:24:45.582724Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
